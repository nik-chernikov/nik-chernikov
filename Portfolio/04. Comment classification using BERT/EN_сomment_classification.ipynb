{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8d18bf-b0d1-4188-ae3e-e5165f3e8c0a",
   "metadata": {},
   "source": "# Comment Classification with BERT"
  },
  {
   "cell_type": "markdown",
   "id": "f72fe711-0f10-4380-8640-6b4a3bc4567b",
   "metadata": {},
   "source": [
    "The Wikishop online store is launching a new service. Now, users can edit and supplement product descriptions, similar to wiki communities. That is, customers offer their edits and comment on others' changes. The store needs a tool that will search for toxic comments and send them for moderation.\n",
    "\n",
    "Train a model to classify comments as either positive or negative. You have a dataset with edit toxicity markup.\n",
    "\n",
    "Build a model with an F1 quality metric value of at least 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d43e5-6506-483f-bd99-9a36540bc3a6",
   "metadata": {},
   "source": "## Preparation"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfbdb2c-4b71-4bd1-aec7-eb8a28d8d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1ac26-ba17-4a2b-b5b8-57071d1335ff",
   "metadata": {},
   "source": "## Data overview"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3168b4f-7241-4cdd-9865-9a3c1c871251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2c2137-a10c-4b39-8b97-c52db0c1ef03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2bc7ccb-1dc9-4d10-9d1c-b4af8d23a6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8903b40-e71a-481a-9e79-be1bd08cbd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70defa-9c88-4a3c-b6d4-47e66693a60e",
   "metadata": {},
   "source": [
    "We have a dataset of 159292 rows. The dataset contains the following features:\n",
    "\n",
    "* `Unnamed: 0` - old index, let's get rid of it right away\n",
    "* `text` - tweet text\n",
    "* `toxic` - tweet toxicity, target feature. Contains values 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769d961-4fa3-4194-8223-8446fe186e1e",
   "metadata": {},
   "source": "## Data preprocessing"
  },
  {
   "cell_type": "markdown",
   "id": "c0a748eb-9445-43e7-a33f-7dcc849a5665",
   "metadata": {},
   "source": "### Removing the old index"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7357350e-8cff-45a2-93e4-4c6f20bfcaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b07ef7-0d16-48d1-a497-d9c319320e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627df4bb-31c2-42fe-8cc8-ada79115a5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db8be88-833e-40f7-b785-c358f7d12c25",
   "metadata": {},
   "source": "### Checking values in the target feature"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3758e4c-5388-432b-8dcf-7b8d40f094ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892bc4a9-e03c-4183-b59c-a1b4c9cde065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dist = df['toxic'].value_counts()\n",
    "target_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93ae81d-8bc5-4014-82c1-7482bc45a196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a bar chart to visualize the distribution of toxic comments in the dataset\n",
    "x = list(target_dist.index)\n",
    "y = target_dist.array\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Toxic comments distribution')\n",
    "plt.grid(visible=True)\n",
    "plt.xticks(x)\n",
    "plt.bar(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a318138-bb3c-456e-8843-e6d6a7bb5db8",
   "metadata": {},
   "source": "In our dataset, the proportion of toxic comments is only about 10%. The dataset is heavily biased towards non-toxic comments."
  },
  {
   "cell_type": "markdown",
   "id": "ddfa82c9-64fa-4d91-9a3f-fd71e6d54452",
   "metadata": {},
   "source": "### Preparing a sample"
  },
  {
   "cell_type": "markdown",
   "id": "5b530c8b-8230-4d70-81df-bca24ba84585",
   "metadata": {},
   "source": "We use only part of the dataset, because creating embeddings and training models on the full dataset can take a lot of time."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69224199-0080-41c6-9cb6-6ebf0e16947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(2000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af3cc6e4-7dcf-46e7-bd5a-1737f6a6a3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sometime back, I just happened to log on to ww...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\nThe latest edit is much better, don't mak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" October 2007 (UTC)\\n\\nI would think you'd be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thanks for the tip on the currency translation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would argue that if content on the Con in co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Welcome!\\n\\nHello, and welcome to Wikipedia.  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Note that the user zzzzz has removed lots of a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>If you seriously believe there are more episod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Stanley Cup Playoffs\\n\\nThe East Conference is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>You're quite right! There can be enclisis with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  toxic\n",
       "0     Sometime back, I just happened to log on to ww...      0\n",
       "1     \"\\n\\nThe latest edit is much better, don't mak...      0\n",
       "2     \" October 2007 (UTC)\\n\\nI would think you'd be...      0\n",
       "3     Thanks for the tip on the currency translation...      0\n",
       "4     I would argue that if content on the Con in co...      0\n",
       "...                                                 ...    ...\n",
       "1995  Welcome!\\n\\nHello, and welcome to Wikipedia.  ...      0\n",
       "1996  Note that the user zzzzz has removed lots of a...      0\n",
       "1997  If you seriously believe there are more episod...      0\n",
       "1998  Stanley Cup Playoffs\\n\\nThe East Conference is...      0\n",
       "1999  You're quite right! There can be enclisis with...      0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4772761b-d681-49e9-bfff-a0a808ff7efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    1786\n",
       "1     214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the target feature\n",
    "df_sample['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d0d3a-512c-4afa-8c72-ae6dad352a6b",
   "metadata": {},
   "source": "## Data preparation"
  },
  {
   "cell_type": "markdown",
   "id": "69d4c4d1-7b26-448f-a9ec-ca5a60e58920",
   "metadata": {},
   "source": [
    "The unitary/toxic-bert model is used to create embeddings\n",
    "\n",
    "Model link: https://huggingface.co/unitary/toxic-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56376b6-535b-4d11-a377-04e3f69d80a7",
   "metadata": {},
   "source": "### Tokenization"
  },
  {
   "cell_type": "markdown",
   "id": "e04b5d33-f334-4187-9989-8b4d16ad14d2",
   "metadata": {},
   "source": "Tokenize the text. We will limit the text length to 512 tokens, as this is the maximum for the model. Add indents and prepare attention_mask."
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03fe65f0-a46b-4373-aee9-7941582b3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained('unitary/toxic-bert')\n",
    "\n",
    "tokenized = df_sample['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, padding='max_length', truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45c24387-38f2-4710-b590-2c319842f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared = np.array([i for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73d4257d-d854-4edd-9000-62e8752c38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 101, 8811, 2067, ...,    0,    0,    0],\n",
       "       [ 101, 1000, 1996, ...,    0,    0,    0],\n",
       "       [ 101, 1000, 2255, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 2065, 2017, ...,    0,    0,    0],\n",
       "       [ 101, 6156, 2452, ...,    0,    0,    0],\n",
       "       [ 101, 2017, 1005, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c43fba-61da-4311-9e56-bf678ce0a990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 512)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23f3610d-8184-46e2-b111-3e1bb60197a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(prepared != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bf6c4bc-ba7c-46c2-98fa-901cf458b309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276ac53-99d7-41a8-bffd-ac80c1536d49",
   "metadata": {},
   "source": "### Converting tokens to embeddings"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0712c277-85a8-48b9-b5ab-d29c8c13fe71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_model = transformers.BertModel.from_pretrained('unitary/toxic-bert')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "embed_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d446418-a186-410f-82e2-8731c2b25193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(model, tokenized_data, attention_mask, batch_size):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(tokenized_data.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(tokenized_data[batch_size*i:batch_size*(i+1)])\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "        batch = batch.to('cuda')\n",
    "        attention_mask_batch = attention_mask_batch.to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dbab217-89b6-4927-9994-ee04d927dec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1941cb4ebed1498e988dee54d2304758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cake\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "embeddings = embed(embed_model, prepared, attention_mask, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff4d3629-fdb1-4e7f-9ee8-b8addbd16541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6170207 , -1.0142671 ,  0.8274097 , ..., -0.8287158 ,\n",
       "         0.5733    ,  0.03446032],\n",
       "       [-0.4693603 , -0.9448781 ,  0.7954195 , ..., -0.63105774,\n",
       "         0.5056714 ,  0.16782281],\n",
       "       [-0.6633926 , -0.9154767 ,  0.4726571 , ..., -0.6053768 ,\n",
       "         0.411482  ,  0.08555199],\n",
       "       ...,\n",
       "       [-0.5558503 , -0.9715062 ,  0.5546094 , ..., -0.75527006,\n",
       "         0.5228087 ,  0.05091452],\n",
       "       [-0.7262837 , -1.1527034 ,  0.7055753 , ..., -0.82303685,\n",
       "         0.3814967 ,  0.19090636],\n",
       "       [-0.7451651 , -0.91121304,  0.65300035, ..., -0.61018914,\n",
       "         0.40986693,  0.17400615]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c3abbc2-66c7-4c9c-9e5d-2c673728b59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6a63a-20e0-42ed-9536-e8c8473689e2",
   "metadata": {},
   "source": "## Training models"
  },
  {
   "cell_type": "markdown",
   "id": "d41f26b4-10b8-43cd-ae45-63d71ab3d461",
   "metadata": {},
   "source": "### Preparing samples"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8869c3a7-874a-4796-9280-4d75b205fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df_sample['toxic'], test_size=0.3, random_state=42, stratify=df_sample['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294707cc-fa85-403d-8e3b-5ad8a15967c5",
   "metadata": {},
   "source": "### Function for GridSearchCV"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ff6d0c4-8bc3-4698-a31d-42a6e63a7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the best model\n",
    "def best_model_search_cv(model, params, n_jobs=-1):\n",
    "    grid = GridSearchCV(model, params, cv=5, n_jobs=n_jobs, scoring='f1', verbose=4)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_estimator_, grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c289c20c-721e-46dd-80f9-42c205b42940",
   "metadata": {},
   "source": "### Logistic Regression"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a655f22-7bdb-478d-a74e-65eaafad560d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Best params: {'C': 100}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1-score of the best model: 0.9134389247247844'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters for the first run of GridSearchCV\n",
    "params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Best parameters obtained after the first run of GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'C': [100]\n",
    "}\n",
    "\n",
    "\n",
    "estimator_lr = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "\n",
    "best_model_lr, best_score_lr, best_params_lr = best_model_search_cv(estimator_lr, params)\n",
    "\n",
    "display(f'Best params: {best_params_lr}')\n",
    "display(f'F1-score of the best model: {best_score_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a5ae2-b094-4a09-bbf6-9578aaf50f61",
   "metadata": {},
   "source": "### Random forest"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c960e8b3-41bc-4c54-a18a-53051318493c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Best params: {'max_depth': 10, 'max_features': 1, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1-score of the best model: 0.9443914493519987'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters for the first run of GridSearchCV\n",
    "params = { \n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['sqrt','log2', 1],\n",
    "    'max_depth' : range(2, 11, 4),\n",
    "    'min_samples_leaf': range(1, 4),\n",
    "    'min_samples_split': range(2, 6, 2)\n",
    "}\n",
    "\n",
    "# Best parameters obtained after the first run of GridSearchCV\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [500],\n",
    "    'max_features': [1],\n",
    "    'max_depth' : [10],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "\n",
    "\n",
    "estimator_rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "best_model_rf, best_score_rf, best_params_rf = best_model_search_cv(estimator_rf, params)\n",
    "\n",
    "display(f'Best params: {best_params_rf}')\n",
    "display(f'F1-score of the best model: {best_score_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f38da7-cd2e-4838-906f-969094d29a0a",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64eba44c-825b-4bfb-8640-cd714d95c559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] Number of positive: 120, number of negative: 1000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107143 -> initscore=-2.120264\n",
      "[LightGBM] [Info] Start training from score -2.120264\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=-1, num_leaves=20;, score=0.903 total time=   0.7s\n",
      "[LightGBM] [Info] Number of positive: 120, number of negative: 1000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195834\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107143 -> initscore=-2.120264\n",
      "[LightGBM] [Info] Start training from score -2.120264\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=-1, num_leaves=20;, score=0.938 total time=   0.7s\n",
      "[LightGBM] [Info] Number of positive: 120, number of negative: 1000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195833\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107143 -> initscore=-2.120264\n",
      "[LightGBM] [Info] Start training from score -2.120264\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=-1, num_leaves=20;, score=0.947 total time=   0.6s\n",
      "[LightGBM] [Info] Number of positive: 120, number of negative: 1000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195834\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107143 -> initscore=-2.120264\n",
      "[LightGBM] [Info] Start training from score -2.120264\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=-1, num_leaves=20;, score=0.933 total time=   0.6s\n",
      "[LightGBM] [Info] Number of positive: 120, number of negative: 1000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195837\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107143 -> initscore=-2.120264\n",
      "[LightGBM] [Info] Start training from score -2.120264\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=-1, num_leaves=20;, score=0.900 total time=   0.6s\n",
      "[LightGBM] [Info] Number of positive: 150, number of negative: 1250\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 1400, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107143 -> initscore=-2.120264\n",
      "[LightGBM] [Info] Start training from score -2.120264\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Best params: {'learning_rate': 0.1, 'max_depth': -1, 'num_leaves': 20}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1-score of the best model: 0.9242855121675155'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters for the first run of GridSearchCV\n",
    "params = {\n",
    "    \"max_depth\": [-1, 6, 10],\n",
    "    \"num_leaves\": [20, 31, 40],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    #\"n_estimators\": [100, 300],\n",
    "    #\"colsample_bytree\": [0.3, 0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "# Best parameters obtained after the first run of GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": [-1],\n",
    "    \"num_leaves\": [20],\n",
    "    \"learning_rate\": [0.1],\n",
    "}\n",
    "\n",
    "\n",
    "estimator_lgb = lgb.LGBMClassifier(objective='binary', n_jobs=-1, random_state=42)\n",
    "\n",
    "best_model_lgb, best_score_lgb, best_params_lgb = best_model_search_cv(estimator_lgb, params,  1)\n",
    "\n",
    "display(f'Best params: {best_params_lgb}')\n",
    "display(f'F1-score of the best model: {best_score_lgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc002fa-b7ee-4e15-a042-f90038508974",
   "metadata": {},
   "source": "### Conclusion"
  },
  {
   "cell_type": "markdown",
   "id": "bad7f049-2ada-4e92-8fb1-d6ca7fc0ef94",
   "metadata": {},
   "source": "Three models were trained: logistic regression, random forest and LightGBM. As a result, the following F1-score metrics were obtained:"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b84f9d5-7474-4887-ae33-423478811e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F1-score'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Logistic Regression: 0.91344'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Random Forest: 0.94439'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LightGBM: 0.92429'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f'F1-score')\n",
    "display(f'Logistic Regression: {best_score_lr.round(5)}')\n",
    "display(f'Random Forest: {best_score_rf.round(5)}')\n",
    "display(f'LightGBM: {best_score_lgb.round(5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967dc47-c735-4a1e-9c76-61a20dc65aa4",
   "metadata": {},
   "source": "The best model was the random forest model."
  },
  {
   "cell_type": "markdown",
   "id": "fd57181d-4dc0-4097-bff3-b5c58fb27034",
   "metadata": {},
   "source": "## Testing the best model"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e0988b8-6f87-4e39-a743-e23ebe916af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F1-score value on the test sample: 0.96183'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_model_rf.predict(X_test)\n",
    "f'F1-score value on the test sample: {f1_score(y_test, predictions).round(5)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2c738-d74d-41ba-a2cc-bd81abc7d0fe",
   "metadata": {},
   "source": "On the test sample, our random forest model showed an F1-score value of 0.96183. This is higher than the required minimum result of 0.75."
  },
  {
   "cell_type": "markdown",
   "id": "4efcad35-4384-4a43-a460-e455da18ea14",
   "metadata": {},
   "source": "## General Conclusion"
  },
  {
   "cell_type": "markdown",
   "id": "6ed0a9f8-60a8-43e4-a133-58ae8796eb00",
   "metadata": {},
   "source": [
    "We have a dataset of 160,000 English-language tweets at our disposal. We needed to train a model that would determine the toxicity of a tweet and have an F1-score metric value of at least 0.75.\n",
    "\n",
    "We prepared a sample and tokenized the text of the tweets. Then, using the unitary/toxic-BERT model, we created embeddings from the tokens.\n",
    "\n",
    "We trained 3 different models using GridSearchCV: logistic regression, random forest, and LightGBM. The random forest model showed the best result.\n",
    "\n",
    "Having tested the random forest model on the test sample, we obtained an F1-score metric value of 0.96183. This is higher than the required minimum result of 0.75. The project goal is achieved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
