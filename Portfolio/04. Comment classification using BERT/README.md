  
# Классификация комментариев с BERT

### Использованные инструменты

PyTorch, BERT, CUDA, pandas, NumPy, Matplotlib, scikit-learn

### Ключевые особенности

Обработка естественных языков (NLP), классификация текстов

### Описание задачи

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75.

### Общий вывод

В нашем распоряжении оказался датасет состоящий из 160000 англоязычных твитов. Нам необходимо было обучить модель, которая бы определяла токсичность твита и имела бы значение метрики f1-score не ниже 0.75. 

Мы подготовили выборку и токенизировали текст твитов. Затем с помощью модели unitary/toxic-bert мы создали из токенов эмбеддинги.

Мы обучили 3 различных модели с использованием GridSearchCV: логистическую регрессию, cлучайный лес и LightGBM. Наилучший результат показала модель случайного леса.

Проверив модель случайного леса на тестовой выборке мы получили значение метрики f1-score равное 0.96183. Это выше требуемого минимального результата в 0.75. Цель проекта выполнена.


